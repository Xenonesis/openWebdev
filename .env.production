# Production Environment Configuration for OpenWebdev
NODE_ENV=production
VITE_NODE_ENV=production

# Application Configuration
APP_NAME="OpenWebdev"
APP_VERSION="2.0.0"
APP_URL="https://openwebdev.com"
APP_DEBUG=false

# Security Configuration
SECURE_COOKIES=true
COOKIE_SAME_SITE=strict
CSRF_PROTECTION=true
RATE_LIMIT_ENABLED=true

# Performance Configuration
ENABLE_COMPRESSION=true
CACHE_STATIC_ASSETS=true
PRELOAD_CRITICAL_RESOURCES=true

# API Configuration
API_TIMEOUT=30000
API_MAX_RETRIES=3
API_RATE_LIMIT_PER_MINUTE=60

# Monitoring & Logging
LOG_LEVEL=warn
VITE_LOG_LEVEL=warn
ENABLE_ANALYTICS=true
SENTRY_ENABLE=true
PERFORMANCE_MONITORING=true

# Get your GROQ API Key here -
# https://console.groq.com/keys
# You only need this environment variable set if you want to use Groq models
GROQ_API_KEY=

# Get your HuggingFace API Key here -
# https://huggingface.co/settings/tokens
# You only need this environment variable set if you want to use HuggingFace models
HuggingFace_API_KEY=

# Get your Open AI API Key by following these instructions -
# https://help.openai.com/en/articles/4936850-where-do-i-find-my-openai-api-key
# You only need this environment variable set if you want to use GPT models
OPENAI_API_KEY=

# Get your Anthropic API Key in your account settings -
# https://console.anthropic.com/settings/keys
# You only need this environment variable set if you want to use Claude models
ANTHROPIC_API_KEY=

# Get your OpenRouter API Key in your account settings -
# https://openrouter.ai/settings/keys
# You only need this environment variable set if you want to use OpenRouter models
OPEN_ROUTER_API_KEY=

# Get your Google Generative AI API Key by following these instructions -
# https://console.cloud.google.com/apis/credentials
# You only need this environment variable set if you want to use Google Generative AI models
GOOGLE_GENERATIVE_AI_API_KEY=

# Production-optimized Chutes API Configuration
CHUTES_API_KEY=cpk_5872af9cbffc432f96e821da9a402c4c.b387316ab5425cf69f617e4328a3c322.CqR5sx6EoO3i3NLdzTjtLrJgxddXVWTx
CHUTES_API_BASE_URL=https://llm.chutes.ai/v1
CHUTES_RATE_LIMIT=100
CHUTES_TIMEOUT=120000

# You only need this environment variable set if you want to use oLLAMA models
# DONT USE http://localhost:11434 due to IPV6 issues
# USE EXAMPLE http://127.0.0.1:11434
OLLAMA_API_BASE_URL=

# You only need this environment variable set if you want to use OpenAI Like models
OPENAI_LIKE_API_BASE_URL=

# You only need this environment variable set if you want to use Together AI models
TOGETHER_API_BASE_URL=

# You only need this environment variable set if you want to use DeepSeek models through their API
DEEPSEEK_API_KEY=

# Get your OpenAI Like API Key
OPENAI_LIKE_API_KEY=

# Get your Together API Key
TOGETHER_API_KEY=

# You only need this environment variable set if you want to use Hyperbolic models
HYPERBOLIC_API_KEY=
HYPERBOLIC_API_BASE_URL=

# Get your Mistral API Key by following these instructions -
# https://console.mistral.ai/api-keys/
# You only need this environment variable set if you want to use Mistral models
MISTRAL_API_KEY=

# Get the Cohere Api key by following these instructions -
# https://dashboard.cohere.com/api-keys
# You only need this environment variable set if you want to use Cohere models
COHERE_API_KEY=

# Get LMStudio Base URL from LM Studio Developer Console
# Make sure to enable CORS
# DONT USE http://localhost:1234 due to IPV6 issues
# Example: http://127.0.0.1:1234
LMSTUDIO_API_BASE_URL=

# Get your xAI API key
# https://x.ai/api
# You only need this environment variable set if you want to use xAI models
XAI_API_KEY=

# Get your Perplexity API Key here - 
# https://www.perplexity.ai/settings/api
# You only need this environment variable set if you want to use Perplexity models
PERPLEXITY_API_KEY=

# Get your AWS configuration
# https://console.aws.amazon.com/iam/home
AWS_BEDROCK_CONFIG=

# Get your GitHub Personal Access Token here -
# https://github.com/settings/tokens
# This token is used for:
# 1. Importing/cloning GitHub repositories without rate limiting
# 2. Accessing private repositories
# 3. Automatic GitHub authentication (no need to manually connect in the UI)
# 
# For classic tokens, ensure it has these scopes: repo, read:org, read:user
# For fine-grained tokens, ensure it has Repository and Organization access
VITE_GITHUB_ACCESS_TOKEN=

# Specify the type of GitHub token you're using
# Can be 'classic' or 'fine-grained'
# Classic tokens are recommended for broader access
VITE_GITHUB_TOKEN_TYPE=

# Netlify Authentication
VITE_NETLIFY_ACCESS_TOKEN=

# Production Context Optimization for qwen2.5-coder:32b
# DEFAULT_NUM_CTX=32768 # Consumes 36GB of VRAM (Production recommended)
# DEFAULT_NUM_CTX=24576 # Consumes 32GB of VRAM
# DEFAULT_NUM_CTX=12288 # Consumes 26GB of VRAM
# DEFAULT_NUM_CTX=6144 # Consumes 24GB of VRAM
DEFAULT_NUM_CTX=24576

# Feature Flags for Production
ENABLE_CHAT=true
ENABLE_WEBCONTAINER=true
ENABLE_FILE_UPLOAD=true
ENABLE_EXPORT=true
ENABLE_GITHUB_INTEGRATION=true
ENABLE_DEPLOYMENT=true

# Build Optimization for Production
BUILD_ANALYZE=false
BUILD_SOURCEMAP=false
BUILD_MINIFY=true
BUILD_TREE_SHAKE=true